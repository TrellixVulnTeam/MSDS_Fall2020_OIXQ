---
title: "Test_1 622"
author: "Salma Elshahawy"
date: "10/29/2020"
output:
  html_document:
    code_folding: show
    df_print: paged
    highlight: tango
    number_section: no
    theme: cosmo
    toc: yes
    toc_float:
      collapsed: yes
      smooth_scroll: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(kableExtra)
library(caret)
library(e1071)
library(class)
library(ROCR)
library(pROC)
```

For this test, we were required to compare performance metrics with HW#1 after applying the two different resampling methods, LOOCV and Bootstrap.
I used the `caret` library and used string `boot` and `loocv` inside method argument within the `train()` to apply different resampling approaches. 

## Dataset 

```{r message=FALSE, warning=FALSE}
df <- data.frame(
  X = as.factor(c(5, 5, 5, 5, 5, 5, 19, 19, 19, 19, 19, 19, 35, 35, 35, 35, 35, 35, 51, 51, 51, 51, 51, 51, 55, 55, 55, 55, 55, 55, 63, 63, 63, 63, 63, 63)),
  Y = c("a","b","c","d","e","f","a","b","c","d","e","f","a","b","c","d","e","f","a","b","c","d","e","f","a","b","c","d","e","f","a","b","c","d","e","f"),
  label = c("BLUE","BLACK","BLUE","BLACK","BLACK","BLACK","BLUE","BLUE","BLUE","BLUE","BLACK","BLUE","BLACK","BLACK","BLUE","BLACK","BLACK","BLACK","BLACK","BLACK","BLUE","BLACK","BLACK","BLACK","BLACK","BLACK","BLACK","BLACK","BLACK","BLACK","BLACK","BLUE","BLUE","BLUE","BLUE","BLUE")
)
df
```

```{r}
set.seed(43)
# define variables for modeling
df$label <- factor(df$label, levels = c("BLACK", "BLUE"))    # BLUE = positive case
xvars <- df[1:2]
xvarsnum <- xvars
xvarsnum$Y <- as.numeric(xvars$Y)   # numeric version of factor variable
yvar <- df[[3]]
# center & scale predictors
prep <- c("center", "scale")
summaryfcn <- function(data, lev = NULL, model = NULL) {
  twoClassSummary(data = data, lev = c("BLUE", "BLACK"), model = model)
}

ctrl <- trainControl(method = "none", 
                     classProbs = TRUE, 
                     savePredictions = TRUE, 
                     summaryFunction = summaryfcn)

##############################################################################
# fit logistic regression model
##############################################################################

lrfit <- train(label ~ ., data = df, 
               method = "glm", 
               family = "binomial",
               preProcess = prep, 
               trControl = ctrl, 
               metric = "Sens")
lrfit
```

```{r}
# training predictions & metrics
lrpred <- predict(lrfit)
lrprob <- predict(lrfit, type = "prob") 
(lrconf <- caret::confusionMatrix(lrpred, yvar, positive = "BLUE"))
```

```{r}
lrroc <- roc(response = yvar, predictor = lrprob[['BLUE']])
```


```{r}
# use numeric predictors
# tunepars = data.frame(k = seq(3))
knnfit <- train(label ~ ., data = df,
                #x = xvarsnum, 
                #y = yvar, 
                method = "knn", 
                preProcess = prep, 
                # tuneGrid = tunepars, 
                #tuneLength = 8,
                trControl = ctrl, 
                metric = "Sens")
knnfit
```

```{r}
# training predictions & metrics
knnpred <- predict(knnfit)
knnprob <- predict(knnfit, type = "prob") 
(knnconf <- caret::confusionMatrix(knnpred, yvar, positive = "BLUE"))
```

```{r}
knnroc <- roc(response = yvar, predictor = knnprob[['BLUE']])

```

## Boot on glm

```{r}
set.seed(43)
# define variables for modeling
df$label <- factor(df$label, levels = c("BLACK", "BLUE"))    # BLUE = positive case
xvars <- df[1:2]
xvarsnum <- xvars
xvarsnum$Y <- as.numeric(xvars$Y)   # numeric version of factor variable
yvar <- df[[3]]
# center & scale predictors
prep <- c("center", "scale")
summaryfcn <- function(data, lev = NULL, model = NULL) {
  twoClassSummary(data = data, lev = c("BLUE", "BLACK"), model = model)
}

ctrlb <- trainControl(method = "boot", 
                     number = 100, 
                     classProbs = TRUE, 
                     savePredictions = TRUE, 
                     summaryFunction = summaryfcn)

##############################################################################
# fit logistic regression model
##############################################################################

lrfitb <- train(label ~ ., data = df, 
               method = "glm", 
               family = "binomial",
               preProcess = prep, 
               trControl = ctrlb, 
               metric = "Sens")
lrfitb
```


```{r}
# training predictions & metrics
lrpredb <- predict(lrfitb)
lrprobb <- predict(lrfitb, type = "prob") 
(lrconfb <- caret::confusionMatrix(lrpredb, yvar, positive = "BLUE"))
```

```{r}
lrrocb <- roc(response = yvar, predictor = lrprobb[['BLUE']])
```

## boot NB

```{r}
set.seed(43)
# use numeric predictors
nbfitb <- train(label ~ ., data = df,
                method = "nb", 
                prob.model = TRUE,
                preProcess = prep, 
                trControl = ctrlb, 
                metric = "Sens")
```

```{r}
# training predictions & metrics
nbpredb <- predict(nbfitb)
nbprobb <- predict(nbfitb, type = "prob") 
(nbconfb <- caret::confusionMatrix(nbpredb, yvar))
```

```{r}
nbrocb <- roc(response = yvar, predictor = nbprobb[['BLUE']])

```

## Boot KNN 

```{r}
knnfitb <- train(label ~ ., data = df,
                #x = xvarsnum, 
                #y = yvar, 
                method = "knn", 
                preProcess = prep, 
                trControl = ctrlb, 
                metric = "Sens")
```

```{r}
# training predictions & metrics
knnpredb <- predict(knnfitb)
knnprobb <- predict(knnfitb, type = "prob") 
(knnconfb <- caret::confusionMatrix(knnpredb, yvar, positive = "BLUE"))
```

```{r}
knnrocb <- roc(response = yvar, predictor = knnprobb[['BLUE']])

```

## LOOCV glm

```{r}
set.seed(43)
ctrllo <- trainControl(method = "LOOCV", 
                     number = 100, 
                     classProbs = TRUE, 
                     p = 0.7,
                     savePredictions = TRUE)

##############################################################################
# fit logistic regression model
##############################################################################
lrfitlo <- train(label ~ ., data = df, 
               method = "glm", 
               family = "binomial",
               preProcess = prep, 
               trControl = ctrllo, 
               metric = "Sens")
lrfitlo
```

```{r}
summary(lrfitlo)
```

```{r}
# training predictions & metrics
lrpredlo <- predict(lrfitlo)
lrproblo <- predict(lrfitlo, type = "prob") 
(lrconflo <- caret::confusionMatrix(lrpredlo, yvar, positive = "BLUE"))
```

```{r}
lrroclo <- roc(response = yvar, predictor = lrproblo[['BLUE']])

```

## LOOCV NB 

```{r}
set.seed(43)
# use numeric predictors
nbfitlo <- train(label ~ ., data = df,
                method = "nb", 
                prob.model = TRUE,
                preProcess = prep, 
                trControl = ctrllo, 
                metric = "Sens")
nbfitlo
```

```{r}
summary(nbfitlo)
```

```{r}
# training predictions & metrics
nbpredlo <- predict(nbfitlo)
nbproblo <- predict(nbfitlo, type = "prob") 
(nbconflo <- caret::confusionMatrix(nbpredlo, yvar))
```

```{r}
nbroclo <- roc(response = yvar, predictor = nbproblo[['BLUE']])

```

## LOOCV KNN

```{r}
# use numeric predictors
# tunepars = data.frame(k = seq(3))
knnfitlo <- train(label ~ ., data = df,
                #x = xvarsnum, 
                #y = yvar, 
                method = "knn", 
                preProcess = prep, 
                # tuneGrid = tunepars, 
                #tuneLength = 8,
                trControl = ctrllo, 
                metric = "Sens")
```

```{r}
# training predictions & metrics
knnpredlo <- predict(knnfitlo)
knnproblo <- predict(knnfitlo, type = "prob") 
(knnconflo <- caret::confusionMatrix(knnpredlo, yvar, positive = "BLUE"))
```

```{r}
knnroclo <- roc(response = yvar, predictor = knnproblo[['BLUE']])

```


```{r}
# summary metrics
modnames <-  c('Basic Logistic Regression', 
               'Basic NB', 
               'Basic KNN',
               'Boot LR', 
               'Boot NB', 
               'Boot KNN',
               'LOOCV LR',
               'LOOCV NB',
               'LOOCV KNN')

acc <- c(
         round(lrconf$overall['Accuracy'], 3),
         '0.821',
         round(knnconf$overall['Accuracy'], 3),
         round(lrconfb$overall['Accuracy'], 3), 
         round(nbconfb$overall['Accuracy'], 3),
         round(knnconfb$overall['Accuracy'], 3),
         round(lrconflo$overall['Accuracy'], 3), 
         round(nbconflo$overall['Accuracy'], 3), 
         round(knnconflo$overall['Accuracy'], 3)) 

sens <- c(
         round(lrconf$byClass['Sensitivity'], 3),
         round(knnconf$byClass['Sensitivity'], 3),
         '0.987',
         round(lrconfb$byClass['Sensitivity'], 3),
         round(nbconfb$byClass['Sensitivity'],3),
         round(knnconfb$byClass['Sensitivity'], 3),
         round(lrconflo$byClass['Sensitivity'], 3),
         round(nbconflo$byClass['Sensitivity'], 3),
         round(knnconflo$byClass['Sensitivity'], 3))

spec <- c(
         round(lrconf$byClass['Specificity'], 3),
         '0.500',
         round(knnconf$byClass['Specificity'], 3),
         round(lrconfb$byClass['Specificity'], 3),
         round(nbconfb$byClass['Specificity'], 3),
         round(knnconfb$byClass['Specificity'], 3),
         round(lrconflo$byClass['Specificity'], 3),
         round(nbconflo$byClass['Specificity'], 3),
         round(knnconflo$byClass['Specificity'], 3))

auc <- c(         
         round(auc(lrroc),3),
         '0.750',
         round(auc(knnroc), 3),
         round(auc(lrrocb),3), 
         round(auc(nbrocb), 3),
         round(auc(knnrocb), 3),
         round(auc(lrroclo), 3), 
         round(auc(nbroclo), 3),
         round(auc(knnroclo), 3))
kappa <- c(
         round(lrconf$overall['Kappa'], 3),
         '0.821',
         round(knnconf$overall['Kappa'], 3),
         round(lrconfb$overall['Kappa'], 3), 
         round(nbconfb$overall['Kappa'], 3),
         round(knnconfb$overall['Kappa'], 3),
         round(lrconflo$overall['Kappa'], 3), 
         round(nbconflo$overall['Kappa'], 3), 
         round(knnconflo$overall['Kappa'], 3)) 
F1 <- c(
         round(lrconf$byClass['F1'], 3),
         '0.500',
         round(knnconf$byClass['F1'], 3),
         round(lrconfb$byClass['F1'], 3),
         round(nbconfb$byClass['F1'], 3),
         round(knnconfb$byClass['F1'], 3),
         round(lrconflo$byClass['F1'], 3),
         round(nbconflo$byClass['F1'], 3),
         round(knnconflo$byClass['F1'], 3))

sum_df <- tibble(Model = modnames, 
                 Accuracy = acc,
                 Sensitivity = sens,
                 Specificity = spec,
                 Kappa = kappa,
                 Auc = auc,
                 F1 = F1)
# kable(sum_df,
#       digits = 3,
#       caption = "Comparison of model performance: Training and resampled metrics")

sum_df
```


## Summary

As shown from the analysis, there is a tight increase in accuracy performance when applying `LOOCV` sampling within the `knn` algorithm from the the `bootstrap` resmpling 0.889 over 0.861. However for `kappa` metric it was relatively better than basic model or using `boot` resampling method. 
Using the bag method on this dataset has almost the same performance as the two other resampling methods. It might have a bigger effect if we have more variables so there would be a room to increase variance during sampling.




