---
title: "Test_1 622"
author: "Salma Elshahawy"
date: "10/29/2020"
output:
  html_document:
    code_folding: show
    df_print: paged
    highlight: tango
    number_section: no
    theme: cosmo
    toc: yes
    toc_float:
      collapsed: yes
      smooth_scroll: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

## Problem statement

Use the dataset you used for HW-1 (Blue/Black)

(A) Run Bagging (ipred package)   

  -- sample with replacement

  -- estimate metrics for a model

  -- repeat as many times as specied and report the average

(B) Run LOOCV (jacknife) for the same dataset

--- iterate over all points

  -- keep one observation as test

  -- train using the rest of the observations

  -- determine test metrics

  -- aggregate the test metrics

end of loop

* find the average of the test metric(s)

* Compare (A), (B) above with the results you obtained in HW-1  and write 3 sentences explaining the observed difference.

## Reading the data 

First we need to construct the data and read it into a dataframe format.

```{r message=FALSE, warning=FALSE}
df <- data.frame(
  X = as.factor(c(5, 5, 5, 5, 5, 5, 19, 19, 19, 19, 19, 19, 35, 35, 35, 35, 35, 35, 51, 51, 51, 51, 51, 51, 55, 55, 55, 55, 55, 55, 63, 63, 63, 63, 63, 63)),
  Y = c("a","b","c","d","e","f","a","b","c","d","e","f","a","b","c","d","e","f","a","b","c","d","e","f","a","b","c","d","e","f","a","b","c","d","e","f"),
  label = c("BLUE","BLACK","BLUE","BLACK","BLACK","BLACK","BLUE","BLUE","BLUE","BLUE","BLACK","BLUE","BLACK","BLACK","BLUE","BLACK","BLACK","BLACK","BLACK","BLACK","BLUE","BLACK","BLACK","BLACK","BLACK","BLACK","BLACK","BLACK","BLACK","BLACK","BLACK","BLUE","BLUE","BLUE","BLUE","BLUE")
)
df
```

## Base line performance of Logistic regression model 

```{r message=FALSE, warning=FALSE}
set.seed(43)
library(caret)
library(ModelMetrics)
library(dplyr)

respCol <- df$label
in_train <- createDataPartition(respCol, p = .70, list = FALSE, times = 1) 
train <- df[in_train,] #training 
test <- df[-in_train,] # test data

# These subsets will help with training and evaluation
training_df_without_label <- train %>% select(-label)
test_df_without_label  <- test %>% select(-label)
training_df_label <- train$label
test_df_label <- test$label

perfALG <- c("LR")
perfAUC = numeric()
perfACC = numeric()
perfTPR = numeric()
perfFPR = numeric()
perfTNR = numeric()
perfFNR = numeric()
```

```{r}
get_lr_yhat <- function(lr_model, data, label_col_name, threshold = 0.5){
  data_levels <- levels(data[[label_col_name]])
  cols_to_keep <- label_col_name != names(data)
  data <- data[,cols_to_keep]
  lr_yhat <- predict(lr_model, data, type = "response")
  lr_yhat <- as.factor(ifelse(lr_yhat <= threshold, data_levels[1], data_levels[2]))
  return(lr_yhat)
}
```


The second will take the the ground truth labels and predicted labels and create metrics for evaluation.


```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(kableExtra)
library(caret)
library(e1071)
library(class)
library(ROCR)
lr_model <- glm(label ~ ., data = train, family = "binomial")
training_lr_yhat <- get_lr_yhat(lr_model, train, "label")
```

```{r}
lr_yhat <- get_lr_yhat(lr_model, test, "label")
test_lr_cm <- caret::confusionMatrix(table(test_df_label, lr_yhat))
# capacity_to_generalize <- evaluate_algo(test_df_label, lr_yhat, "LR")

```

```{r}
test_lr_cm
```

```{r}
set.seed(43)
start_tm <- proc.time()
df<-train
runModel<-function(df) {naiveBayes(label~.,data=df[sample(1:nrow(df),nrow(df),replace=T),])}
lapplyrunmodel <- function(x)runModel(df)

system.time(models_bag<-lapply(1:100,lapplyrunmodel))
```

```{r}
object.size(models_bag)
```

```{r}
models_bag
```

```{r}
bag_preds<-lapply(models_bag,FUN=function(M,D=test[,-c(3)])predict(M,D,type='class'))

bag_cfm<-lapply(bag_preds,FUN=function(P,A=test[[3]])
{pred_class<-unlist(P)
  pred_tbl<-table(A,pred_class)
  pred_cfm<-caret::confusionMatrix(pred_tbl)
  pred_cfm
})

```


```{r}
bag_cfm
```

```{r}
bag.perf<-as.data.frame(do.call('rbind',lapply(bag_cfm,FUN=function(cfm)c(cfm$overall, cfm$byClass))))
bag.perf

```

```{r}
library(skimr)
skim(bag.perf)
```
