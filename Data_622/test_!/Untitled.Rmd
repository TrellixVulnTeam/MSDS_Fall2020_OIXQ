---
title: "Untitled"
author: "Salma Elshahawy"
date: "11/3/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

## R Markdown

```{r message=FALSE, warning=FALSE}
df <- data.frame(
  X = as.factor(c(5, 5, 5, 5, 5, 5, 19, 19, 19, 19, 19, 19, 35, 35, 35, 35, 35, 35, 51, 51, 51, 51, 51, 51, 55, 55, 55, 55, 55, 55, 63, 63, 63, 63, 63, 63)),
  Y = c("a","b","c","d","e","f","a","b","c","d","e","f","a","b","c","d","e","f","a","b","c","d","e","f","a","b","c","d","e","f","a","b","c","d","e","f"),
  label = c("BLUE","BLACK","BLUE","BLACK","BLACK","BLACK","BLUE","BLUE","BLUE","BLUE","BLACK","BLUE","BLACK","BLACK","BLUE","BLACK","BLACK","BLACK","BLACK","BLACK","BLUE","BLACK","BLACK","BLACK","BLACK","BLACK","BLACK","BLACK","BLACK","BLACK","BLACK","BLUE","BLUE","BLUE","BLUE","BLUE")
)
df
```

## Base model

```{r}
library(dplyr)
set.seed(43)
in_training_set <- createDataPartition(df$label, p = 0.8, list = FALSE, times = 1)
train <- df[in_training_set,]
test  <- df[-in_training_set,]
# These subsets will help with training and evaluation
training_df_without_label <- train %>% select(-label)
test_df_without_label  <- test %>% select(-label)
training_df_label <- train$label
test_df_label <- test$label
```

```{r}
get_lr_yhat <- function(lr_model, data, label_col_name, threshold = 0.5){
  data_levels <- levels(data[[label_col_name]])
  cols_to_keep <- label_col_name != names(data)
  data <- data[,cols_to_keep]
  lr_yhat <- predict(lr_model, data, type = "response")
  lr_yhat <- as.factor(ifelse(lr_yhat <= threshold, data_levels[1], data_levels[2]))
  return(lr_yhat)
}
```


The second will take the the ground truth labels and predicted labels and create metrics for evaluation.


```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(kableExtra)
library(caret)
library(e1071)
library(class)
library(ROCR)
lr_model <- glm(label ~ ., data = train, family = "binomial")
training_lr_yhat <- get_lr_yhat(lr_model, train, "label")
```

```{r}
lr_yhat <- get_lr_yhat(lr_model, test, "label")
test_lr_cm <- caret::confusionMatrix(table(test_df_label, lr_yhat))
```

```{r}
test_lr_cm
```

```{r}
set.seed(43)
df$label <- factor(df$label, levels = c("BLACK", "BLUE"))    # BLUE = positive case
xvars <- df[1:2]
xvarsnum <- xvars
xvarsnum$Y <- as.numeric(xvars$Y)   # numeric version of factor variable
yvar <- df[[3]]
# center & scale predictors
prep <- c("center", "scale")
# repeated 100-Bagging method; set BLUE = positive case
summaryfcn <- function(data, lev = NULL, model = NULL) {
  twoClassSummary(data = data, lev = c("BLUE", "BLACK"), model = model)
}
ctrl <- trainControl(method = "boot", 
                     number = 100, 
                     classProbs = TRUE, 
                     savePredictions = TRUE, 
                     summaryFunction = summaryfcn)

# use numeric predictors
svmfit <- train(label ~ ., data = df,
                # x = df$X,
                # y = yvar,  
                method = "svmRadial", prob.model = TRUE,
                preProcess = prep,
                #tuneGrid = tunepars, 
                trControl = ctrl, 
                metric = "Sens")
svmfit
```

```{r}
# training predictions & metrics
svmpred <- predict(svmfit)
svmprob <- predict(svmfit, type = "prob") 
(svmconf <- caret::confusionMatrix(svmpred, yvar))
```

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(kableExtra)
library(caret)
library(e1071)
library(class)
library(ROCR)
library(pROC)
svmroc <- roc(response = yvar, predictor = svmprob[['BLUE']])
plot(svmroc)
```

## Using Bootstrapping

```{r}
library(caret)
# define variables for modeling
df$label <- factor(df$label, levels = c("BLACK", "BLUE"))    # BLUE = positive case
xvars <- df[1:2]
xvarsnum <- xvars
xvarsnum$Y <- as.numeric(xvars$Y)   # numeric version of factor variable
yvar <- df[[3]]
# center & scale predictors
prep <- c("center", "scale")
# repeated 100-Bagging method; set BLUE = positive case
summaryfcn <- function(data, lev = NULL, model = NULL) {
  twoClassSummary(data = data, lev = c("BLUE", "BLACK"), model = model)
}
ctrl <- trainControl(method = "boot", 
                     number = 100, 
                     classProbs = TRUE, 
                     savePredictions = TRUE, 
                     summaryFunction = summaryfcn)

##############################################################################
# fit logistic regression model; no tuning 
##############################################################################

set.seed(43)
lrfit <- train(label ~ ., data = df, 
               #x = xvars, 
               #y = yvar, 
               method = "glm", family = "binomial",
               preProcess = prep, 
               #tuneGrid = tunepars, 
               trControl = ctrl, 
               metric = "Sens")
lrfit
```

```{r}
summary(lrfit)

```

```{r}
# training predictions & metrics
lrpred <- predict(lrfit)
lrprob <- predict(lrfit, type = "prob") 
(lrconf <- confusionMatrix(lrpred, yvar, positive = "BLUE"))
```

## LOOCV

```{r}
ctrl_2 <- trainControl(method = "LOOCV", 
                     number = 100, 
                     classProbs = TRUE, 
                     savePredictions = TRUE)

##############################################################################
# fit logistic regression model; no tuning 
##############################################################################
#tunepars = data.frame()
set.seed(1012)
lrfit2 <- train(label ~ ., data = df, 
               #x = xvars, 
               #y = yvar, 
               method = "glm", family = "binomial",
               preProcess = prep, 
               #tuneGrid = tunepars, 
               trControl = ctrl_2, 
               metric = "Sens")
lrfit2
```

```{r}
summary(lrfit2)
```

```{r}
# training predictions & metrics
lrpred2 <- predict(lrfit2)
lrprob2 <- predict(lrfit2, type = "prob") 
(lrconf2 <- confusionMatrix(lrpred2, yvar, positive = "BLUE"))
```

